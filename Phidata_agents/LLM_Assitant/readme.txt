Building a LLM Assistant with Memory (for session context), Knowledge (domain-specific information via vector
databases i.e. RAG), and Tools (custom Python functions for real-world actions) enabling continuous conversations.
